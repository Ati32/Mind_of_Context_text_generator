{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohqhaVE63F3k"
      },
      "source": [
        "# Basic Transformer model for Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRq9ydqP3MqU"
      },
      "source": [
        "Based on (code): https://github.com/MLWhiz/data_science_blogs/blob/master/transformers/Translator.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2fsAlqU3Fo5"
      },
      "source": [
        "Based on (paper): https://drive.google.com/viewerng/viewer?url=https://arxiv.org/pdf/1706.03762.pdf   \n",
        "and also: https://medium.com/@galhever/neural-machine-translation-with-transformers-69d4bf918299"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjUsMYTMMgsN",
        "outputId": "064d6d0f-9a5f-45bf-fa05-b1c3754a53f2"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.nn.init import xavier_uniform_\n",
        "from torch import Tensor\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "#seaborn.set_context(context=\"talk\")\n",
        "%matplotlib inline\n",
        "from torchtext import data, datasets\n",
        "from torchtext.data import TabularDataset\n",
        "import spacy\n",
        "\n",
        "from typing import Optional, Any\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eddkg4gyNVXM"
      },
      "source": [
        "BOS_WORD = '<s>' # beginning of sentence token\n",
        "EOS_WORD = '</s>' # end of sentence token\n",
        "BLANK_WORD = \"<blank>\" # blank token for padding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZwAAW4AUawy",
        "outputId": "ecf914f9-b387-4e42-8ce0-2aa393198205"
      },
      "source": [
        "word_tokenize('á ő ü ó é ö ') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['á', 'ő', 'ü', 'ó', 'é', 'ö']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOY_mkxcRciM"
      },
      "source": [
        "SRC = data.Field(tokenize=word_tokenize, pad_token=BLANK_WORD)\n",
        "TGT = data.Field(tokenize=word_tokenize, init_token = BOS_WORD,\n",
        "eos_token = EOS_WORD, pad_token=BLANK_WORD)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7mGka7xJmCI"
      },
      "source": [
        "fields = [('tgt',TGT), ('src',SRC)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3YY1VlCzwy9"
      },
      "source": [
        "### Loading the English-Hungarian sentence pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN1d8W7O6PFf"
      },
      "source": [
        "The training set contains ~74000 sentence pairs, while the validation set has ~13000 sentences. No test set since the translations need to be evaluated by humans, so I'll just use a couple simple sentences for testing at the end and check each of them. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5caHF6e53I6"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywC6pvGASdi-"
      },
      "source": [
        "84000 sentence pair data (source: http://www.manythings.org/anki/):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUX5eO3LSimL"
      },
      "source": [
        "Hunglish data (source: http://mokk.bme.hu/resources/hunglishcorpus/):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdVpy5m5duCz"
      },
      "source": [
        "train_data, valid_data = TabularDataset.splits(\n",
        "    path='/content/drive/My Drive/AML_projekt',\n",
        "    train = 'hunglish_train_cut_p1.tsv',\n",
        "    validation = 'hunglish_valid_2_p1c.tsv',\n",
        "    format ='tsv',\n",
        "    fields= fields\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZI1qjipJ-zL",
        "outputId": "634b2d91-b12a-4d33-9115-7142ce2b7b8a"
      },
      "source": [
        "print(vars(valid_data[14])['tgt'])\n",
        "#print(train_data[0].__dict__.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['-', 'El', 'kell', 'őt', 'választani', 'a', 'társaitól', ',', 'Uram', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8zmDgQI0OuU"
      },
      "source": [
        "Take a look at the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pO1G7Cxz8RS",
        "outputId": "d98a0c79-e443-4a2a-cc55-c4671a663a09"
      },
      "source": [
        "for i, example in enumerate([(x.src,x.tgt) for x in train_data[:15]]):\n",
        "    print(f\"Example_{i}:{example}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example_0:(['The', 'people', 'stared', '.'], ['Az', 'emberek', 'rámeredtek', '.'])\n",
            "Example_1:(['The', 'hands', '.'], ['A', 'kezek', '?'])\n",
            "Example_2:(['If', 'the', 'Second', 'Foundation', 'exists', 'and', 'wishes', 'to', 'guard', 'the', 'secret', 'of', 'that', 'existence', ',', 'then', 'one', 'thing', 'is', 'sure', '.'], ['Ha', 'a', 'Második', 'Alapítvány', 'létezik', ',', 'és', 'létezésének', 'titkát', 'meg', 'akarja', 'őrizni', ',', 'akkor', 'egyvalamit', 'biztosra', 'vehetünk', '.'])\n",
            "Example_3:(['She', 'shot', 'an', 'enquiring', 'look', 'up', 'at', 'Standish', '.'], ['Érdeklődő', 'pillantást', 'vetett', 'Standish-re', '.'])\n",
            "Example_4:(['I', 'kissed', 'my', 'baby', 'and', 'we', 'put', 'out', 'the', 'lights', '.'], ['Megcsókoltam', 'Terryt', ',', 'és', 'eloltottuk', 'a', 'lámpát', '.'])\n",
            "Example_5:(['Then', 'there', \"'s\", 'a', 'travelling', 'company', 'of', 'dwarves', 'going', 'West', 'come', 'in', 'this', 'evening', '.'], ['Aztán', 'ma', 'este', 'törpök', 'jöttek', ':', 'ők', 'nyugat', 'felé', 'tartanak', '.'])\n",
            "Example_6:(['Psychohistory', 'does', 'sound', 'better', ',', 'but', 'I', 'do', \"n't\", 'know', 'what', 'it', 'is', '.'], ['-', 'A', 'pszichohistória', 'jobban', 'hangzik', ',', 'de', 'én', 'még', 'így', 'sem', 'tudom', ',', 'mi', 'az', '.'])\n",
            "Example_7:(['I', 'admire', 'her', 'at', 'last', '-', 'between', 'ourselves', ',', 'I', \"'ve\", 'always', 'detested', 'the', 'old', 'girl', '.', \"''\"], ['Végül', 'is', 'csodálom', '...', 'maradjon', 'köztünk', ',', 'én', 'mindig', 'megvetettem', 'az', 'öreglányt', '.'])\n",
            "Example_8:(['`That', 'is', ',', 'the', 'night', ',', 'my', 'lord', ',', \"'\", 'I', 'answered', '.'], ['-', 'Inkább', 'holdvilágot', ',', 'kegyelmes', 'uram', '-', 'válaszoltam', '.'])\n",
            "Example_9:(['The', 'nymphs', 'were', 'fat', ',', 'furry', 'spheres', ',', 'full', 'of', 'bounce', 'and', 'mindless', 'energy', '.'], ['A', 'nimfák', 'pufók', ',', 'szőrös', ',', 'csupa', 'élet', 'és', 'energia', 'gömböcök', 'voltak', '.'])\n",
            "Example_10:(['It', 'was', 'a', 'strange', 'mixture', 'with', 'his', 'underlying', 'awe', 'at', 'being', 'on', 'Rakis', '.'], ['Ez', 'furcsán', 'keveredett', 'azzal', ',', 'hogy', 'rakisi', 'tartózkodása', 'félelmes', 'áhítattal', 'töltötte', 'el', '.'])\n",
            "Example_11:(['Let', 'us', 'here', 'emphasize', 'one', 'detail', ',', 'he', 'was', 'not', 'won', 'over', 'and', 'was', 'but', 'little', 'softened', 'by', 'all', 'the', 'solicitude', 'and', 'tenderness', 'of', 'his', 'grandfather', '.'], ['Hangsúlyoznunk', 'kell', 'itt', ',', 'hogy', 'nagyapjának', 'gondoskodása', 'és', 'gyengédsége', 'egyáltalán', 'nem', 'fegyverezte', 'le', 'és', 'csak', 'kevéssé', 'hatotta', 'meg', '.'])\n",
            "Example_12:(['Bagman', 'suddenly', 'spotted', 'Harry', ',', 'got', 'up', 'quickly', ',', 'and', 'bounded', 'forward', '.'], ['Mikor', 'Bumfolt', 'észrevette', 'az', 'ajtóban', 'álló', 'Harryt', ',', 'nyomban', 'felpattant', ',', 'és', 'odadöcögött', 'hozzá', '.'])\n",
            "Example_13:(['It', 'sounds', 'like', 'a', 'little', 'trick', ',', 'but', 'it', \"'s\", 'quite', 'unbeatable', '.', \"''\"], ['Apró', 'kis', 'trükknek', 'hangzik', ',', 'de', 'csalhatatlan', '.'])\n",
            "Example_14:(['Can', 'you', 'tell', 'me', 'why', 'you', 'foster', 'the', 'cruel', 'deception', '?', \"''\"], ['Miért', 'adtok', 'tápot', 'ennek', 'a', 'könyörtelen', 'csalásnak', '?'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuOpgGIB0Wuu"
      },
      "source": [
        "Next I also create vocabularies, containing those words only that appear at least MIN_FREQ times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCCqpTrIzihE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cada9faa-8a1e-4f3e-f9ba-74d7c77fbce9"
      },
      "source": [
        "MIN_FREQ = 3\n",
        "SRC.build_vocab(valid_data.src, min_freq=MIN_FREQ, vectors='glove.6B.100d') # tried adding the file manually but it doesn't work, it has to download it every time\n",
        "TGT.build_vocab(valid_data.tgt, min_freq=MIN_FREQ)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:29, 2.21MB/s]                           \n",
            " 99%|█████████▉| 397877/400000 [00:17<00:00, 21368.51it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqjK1yHP3hHA",
        "outputId": "25ea34fa-223c-41ee-efe9-51c7f9dea18c"
      },
      "source": [
        "len(SRC.vocab) #11104"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11104"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA-3xSCR7Vna",
        "outputId": "314d82ad-4c11-41a0-fd7d-e3b2ce55a9b7"
      },
      "source": [
        "len(TGT.vocab) #14366"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14366"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyB9wjnT0zUd"
      },
      "source": [
        " Create iterators to process text in batches of approx. the same length (they are sorted by length) to avoid problems with memory. The validation batch size is 1 to avoid padding on the val. sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q8JkcFW0hS7"
      },
      "source": [
        "BATCH_SIZE = 25\n",
        "train_iter = data.BucketIterator(train_data, batch_size=BATCH_SIZE, repeat=False, sort_key=lambda x: len(x.src))\n",
        "val_iter = data.BucketIterator(valid_data, batch_size=1, repeat=False, sort_key=lambda x: len(x.src))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2TfSBD1Ds6"
      },
      "source": [
        "Let's see what's in a batch (will be the input to the network):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCCYJCmu0-6r",
        "outputId": "3fc2fbb4-ed85-4466-9d2f-8ea5613992a4"
      },
      "source": [
        "batch = next(iter(train_iter))\n",
        "src_matrix = batch.src.T\n",
        "print(src_matrix, src_matrix.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[   74,    75,    15,    31,    24,   252,  1094,    70,   717,    69,\n",
            "         10997,     2,    15,   204,   209,    14,    11,  1559,   260,     3,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   30,   262,  3221,    69,     4,  1388,   557,     2,  3055,     4,\n",
            "          9892,     6,   958,  5948,   225,     4,  6031,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  274,   615,    51,     0,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  101,    10,    65,   105,    16,  4566,    61,   356,     4,  5791,\n",
            "             6,     4,   273,   563,   406,   300,     2,    14,    10,   121,\n",
            "           423,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   29,   464,  3469,    59,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  458,    10,   112,   315,   222,   138,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [    9,   167,  1748,     6,  1454,  1244,    46,    12,     2,    19,\n",
            "             9,    23,     3,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   30,   206,    12,  2597,    77,   419,    44,  6885,    51,    31,\n",
            "            60,     0,    59,   597,    11,     4,   210,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  337,    59,  9798,     6,   489,    77,  8155,    66,    13,  5526,\n",
            "            13,    17,    60,  9633,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   29,  1067,   522,    37,  1358,    14,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  729,    41,     5,   609,     9,   160,  1336,     7,   683,    15,\n",
            "            20,   181,   183,     2,    81,    70,   424,     7,    52,  2763,\n",
            "            27,   181,    64,   416,     0,    12,    15,    62,     4,     0,\n",
            "             6,   928,   904,     3],\n",
            "        [   80,   306,  3636,  2896,     5,   780,   375,   118,     3,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  417,    44,   276,    70,   164,     0,    18,    19,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  165,    22,     4,  1686,     0,    35,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  208,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  692,  2653,   124,     8,   335,  1003,     2,  1172,    12,    44,\n",
            "            66,    24,  4214,    32,    43,   920,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  547,  1030,   129,    40,    78,     8,  1825,     0,    21,     3,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   93,   262,    11,  3302,  4116,   318,     4,   958,     2,  2907,\n",
            "            65,    84,   953,    11,    50,   188,    98,    11,     4,  5108,\n",
            "            38,    40,   879,  1290,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  221,  1017,  1697,   631,     4,   210,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  211,    37,    15,  1154,   121,   130,    11,     4,  5387,    21,\n",
            "           389,   344,     3,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  298,  4054,    40,  3080,   847,    42,  3694,     2,     5,   303,\n",
            "             0,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [   99,   601,     0,  1360,     0,     4,    87,     6,    16,   156,\n",
            "             3,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [    0,     0,    11,     0,     0,     2,     0,    41,     0,    11,\n",
            "             0,     0,     2,  6576,     0,    11,     0,     2,     0,     0,\n",
            "             0,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  505,    35,     0,    35,    19,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1],\n",
            "        [  592,     2,   240,    46,   588,    15,    52,  1421,     3,    19,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1]]) torch.Size([25, 34])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZtgcbeA1MEX",
        "outputId": "9d8977cd-2f49-4d2c-991a-28cf6baffbef"
      },
      "source": [
        "tgt_matrix = batch.tgt.T\n",
        "print(tgt_matrix, tgt_matrix.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[    2,   186,    28,   573,    22,    11,     0,     0,     4,  4009,\n",
            "           612,  2084,     5,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   413,   136,     8,     0,  4593,     4,   657,     6,     0,\n",
            "             0,  1949,     0,     5,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,   968,     6,     0,     5,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,    11, 11153,     0,     8,    82,  1404,     0,     6,\n",
            "             0,     5,     3,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,    14,     0,  6010,  9253,  5341,     5,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   405,  5110,   910,    16,     5,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,    95,     4,   370,    46,  9169,     5,     3,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,  2795,     4,    10,   516,    38, 13871,   220,     0,    29,\n",
            "            46,     8,     0,     5,     3,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,    78,     0,     4,    15,     0,    31,   249,  3290,     4,\n",
            "            10,     0,     5,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     7,    36,     6,   887,    11,   486,     4,    11,    56,\n",
            "            17,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     7,   590,     4,  2099,     4,    20,   820,   190,  1926,\n",
            "            95,     4,    10,   466,     0,     0,     4,   137,    71,     0,\n",
            "           268,     0,    35,  2403,    34,  1495,    27,    53,   535,  1951,\n",
            "         11974,     5,     3],\n",
            "        [    2,  3063,   130,     0,     4,    20,     0,  2574,    18,     6,\n",
            "          1071,     5,     3,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,    49,    14,     0,    13,    14,     0,    12,     3,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,    49,    59,     6,     0,    17,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   129,    12,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   589,    15,   357,  1505,  3501,     4,   228,   123,     4,\n",
            "            10,    35,  3327,     0,    18,     6,     0,     5,     3,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,  1596,    42,   156,     4,    26,    15,     0,     0,\n",
            "             5,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,     0,   780,     6,     0,  4048,     4,   504,   722,\n",
            "           110,  7459,   172, 10200,     4,    26,  2256,  8577,     0,   722,\n",
            "             5,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   455,     0, 11079,     6,  1882,     5,     3,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   201,    84,     0,     6,  4737,    91,  4095,     5,     3,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,   263,  9680,     4,     0,     9,    11,     0,  1570,   102,\n",
            "             5,     3,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,    14,     0,  6059,     0,   616,     0,  8546,     5,     3,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     7,     0,     0,  3910,     0,     0,     4,     0,    25,\n",
            "             0,  3910,     0,     0,     4,     0,     0,  3910,     0,     4,\n",
            "             0,     0,     0,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,    17,     3,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1],\n",
            "        [    2,     0,    18,     6,     0,     5,     3,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
            "             1,     1,     1]]) torch.Size([25, 33])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXhqELFdZJuL",
        "outputId": "297b5f7c-8d5a-414e-a985-a413b4af891e"
      },
      "source": [
        "print(SRC.vocab.itos[1])\n",
        "print(TGT.vocab.itos[2])\n",
        "print(SRC.vocab.itos[3])\n",
        "print(TGT.vocab.itos[154])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<blank>\n",
            "<s>\n",
            ".\n",
            "akik\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6oBu_kG25CD"
      },
      "source": [
        "### Creating the Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUJ1gy7227zY"
      },
      "source": [
        "There is a Pytorch Transformer implementation, but that lacks some features included in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z19219o1PwI"
      },
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.d_model = d_model\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x * math.sqrt(self.d_model)\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "    \n",
        "class MyTransformer(nn.Module):\n",
        "    def __init__(self, d_model: int = 512, nhead: int = 8, num_encoder_layers: int = 6,\n",
        "                 num_decoder_layers: int = 6, dim_feedforward: int = 2048, dropout: float = 0.1,\n",
        "                 activation: str = \"relu\",source_vocab_length: int = 60000,target_vocab_length: int = 60000) -> None:\n",
        "        super(MyTransformer, self).__init__()\n",
        "        self.source_embedding = nn.Embedding(source_vocab_length, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
        "        encoder_norm = nn.LayerNorm(d_model)\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)\n",
        "        self.target_embedding = nn.Embedding(target_vocab_length, d_model)\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)\n",
        "        decoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)\n",
        "        self.out = nn.Linear(512, target_vocab_length)\n",
        "        self._reset_parameters()\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def forward(self, src: Tensor, tgt: Tensor, src_mask: Optional[Tensor] = None, tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None, src_key_padding_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None, memory_key_padding_mask: Optional[Tensor] = None) -> Tensor:\n",
        "        if src.size(1) != tgt.size(1):\n",
        "            raise RuntimeError(\"the batch number of src and tgt must be equal\")\n",
        "        src = self.source_embedding(src)\n",
        "        src = self.pos_encoder(src)\n",
        "        memory = self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
        "        tgt = self.target_embedding(tgt)\n",
        "        tgt = self.pos_encoder(tgt)\n",
        "        output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n",
        "                              tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                              memory_key_padding_mask=memory_key_padding_mask)\n",
        "        output = self.out(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        r\"\"\"Initiate parameters in the transformer model.\"\"\"\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                xavier_uniform_(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoAv7dCU30z2"
      },
      "source": [
        "Initializing the transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLb0mqEZ2jik",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235e8733-8b0c-4e37-bf10-f9b39a17d30a"
      },
      "source": [
        "source_vocab_length = len(SRC.vocab)\n",
        "target_vocab_length = len(TGT.vocab)\n",
        "\n",
        "model = MyTransformer(source_vocab_length=source_vocab_length,target_vocab_length=target_vocab_length)\n",
        "optim = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9) # same parameters as in the paper\n",
        "model = model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r 99%|█████████▉| 397877/400000 [00:30<00:00, 21368.51it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3erGQ-Z33c_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d10201-276d-408c-d68a-26447f57e9b7"
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "140500"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjK2xAzy4dHN"
      },
      "source": [
        "def train(train_iter, val_iter, model, optim, num_epochs,use_gpu=True): \n",
        "    train_losses = []\n",
        "    valid_losses = []\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = 0\n",
        "        valid_loss = 0\n",
        "        # Train model\n",
        "        model.train()\n",
        "        for i, batch in enumerate(train_iter):\n",
        "            src = batch.src.cuda() if use_gpu else batch.src\n",
        "            tgt = batch.tgt.cuda() if use_gpu else batch.tgt\n",
        "            #change to shape (bs , max_seq_len)\n",
        "            src = src.transpose(0,1)\n",
        "            #change to shape (bs , max_seq_len+1) , Since right shifted\n",
        "            tgt = tgt.transpose(0,1)\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            targets = tgt[:, 1:].contiguous().view(-1)\n",
        "            src_mask = (src != 0)\n",
        "            src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
        "            src_mask = src_mask.cuda() if use_gpu else src_mask\n",
        "            tgt_mask = (tgt_input != 0)\n",
        "            tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n",
        "            tgt_mask = tgt_mask.cuda() if use_gpu else tgt_mask\n",
        "            size = tgt_input.size(1)\n",
        "            #print(size)\n",
        "            np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
        "            np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
        "            np_mask = np_mask.cuda() if use_gpu else np_mask   \n",
        "            # Forward, backprop, optimizer\n",
        "            optim.zero_grad()\n",
        "            preds = model(src.transpose(0,1), tgt_input.transpose(0,1), tgt_mask = np_mask)#, src_mask = src_mask)#, tgt_key_padding_mask=tgt_mask)\n",
        "            preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))\n",
        "            loss = F.cross_entropy(preds,targets, ignore_index=0,reduction='sum')\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            train_loss += loss.item()/BATCH_SIZE\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(val_iter):\n",
        "                src = batch.src.cuda() if use_gpu else batch.src\n",
        "                tgt = batch.tgt.cuda() if use_gpu else batch.tgt\n",
        "                #change to shape (bs , max_seq_len)\n",
        "                src = src.transpose(0,1)\n",
        "                #change to shape (bs , max_seq_len+1) , Since right shifted\n",
        "                tgt = tgt.transpose(0,1)\n",
        "                tgt_input = tgt[:, :-1]\n",
        "                targets = tgt[:, 1:].contiguous().view(-1)\n",
        "                src_mask = (src != 0)\n",
        "                src_mask = src_mask.float().masked_fill(src_mask == 0, float('-inf')).masked_fill(src_mask == 1, float(0.0))\n",
        "                src_mask = src_mask.cuda() if use_gpu else src_mask\n",
        "                tgt_mask = (tgt_input != 0)\n",
        "                tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n",
        "                tgt_mask = tgt_mask.cuda() if use_gpu else tgt_mask\n",
        "                size = tgt_input.size(1)\n",
        "                #print(size)\n",
        "                np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
        "                np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
        "                np_mask = np_mask.cuda() if use_gpu else np_mask\n",
        "\n",
        "                preds = model(src.transpose(0,1), tgt_input.transpose(0,1), tgt_mask = np_mask)#, src_mask = src_mask)#, tgt_key_padding_mask=tgt_mask)\n",
        "                preds = preds.transpose(0,1).contiguous().view(-1, preds.size(-1))         \n",
        "                loss = F.cross_entropy(preds,targets, ignore_index=0,reduction='sum')\n",
        "                valid_loss += loss.item()/1\n",
        "            \n",
        "        # Log after each epoch\n",
        "        print(f'''Epoch [{epoch+1}/{num_epochs}] complete. Train Loss: {train_loss/len(train_iter):.3f}. Val Loss: {valid_loss/len(val_iter):.3f}''')\n",
        "        \n",
        "        #Save best model till now:\n",
        "        #if valid_loss/len(val_iter)<min(valid_losses,default=1e9): \n",
        "        #    print(\"saving state dict\")\n",
        "        #    torch.save(model.state_dict(), f\"checkpoint_best_epoch.pt\")\n",
        "\n",
        "        #Save best model till now:\n",
        "        if train_loss/len(train_iter)<min(train_losses,default=1e9): \n",
        "            print(\"saving state dict\")\n",
        "            torch.save(model.state_dict(), f\"checkpoint_best_epoch.pt\")\n",
        "        \n",
        "        train_losses.append(train_loss/len(train_iter))\n",
        "        valid_losses.append(valid_loss/len(val_iter))\n",
        "        \n",
        "        # Check Example after each epoch:\n",
        "        sentences = [\"This is an example to check how our model is performing.\"]\n",
        "        for sentence in sentences:\n",
        "            print(f\"Original Sentence: {sentence}\")\n",
        "            print(f\"Translated Sentence: {greeedy_decode_sentence(model,sentence)}\")\n",
        "    return train_losses,valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVnhc1d75Hv9"
      },
      "source": [
        "def greeedy_decode_sentence(model,sentence):\n",
        "    model.eval()\n",
        "    sentence = SRC.preprocess(sentence)\n",
        "    indexed = []\n",
        "    for tok in sentence:\n",
        "        if SRC.vocab.stoi[tok] != 0 :\n",
        "            indexed.append(SRC.vocab.stoi[tok])\n",
        "        else:\n",
        "            indexed.append(0)\n",
        "    sentence = Variable(torch.LongTensor([indexed])).cuda()\n",
        "    tgt_init_tok = TGT.vocab.stoi[BOS_WORD]\n",
        "    tgt = torch.LongTensor([[tgt_init_tok]]).cuda()\n",
        "    translated_sentence = \"\"\n",
        "    maxlen = 25\n",
        "    for i in range(maxlen):\n",
        "        size = tgt.size(0)\n",
        "        np_mask = torch.triu(torch.ones(size, size)==1).transpose(0,1)\n",
        "        np_mask = np_mask.float().masked_fill(np_mask == 0, float('-inf')).masked_fill(np_mask == 1, float(0.0))\n",
        "        np_mask = np_mask.cuda()\n",
        "        pred = model(sentence.transpose(0,1), tgt, tgt_mask = np_mask)\n",
        "        add_word = TGT.vocab.itos[pred.argmax(dim=2)[-1]]\n",
        "        translated_sentence+=\" \"+add_word\n",
        "        if add_word==EOS_WORD:\n",
        "            break\n",
        "        tgt = torch.cat((tgt,torch.LongTensor([[pred.argmax(dim=2)[-1]]]).cuda()))\n",
        "        #print(tgt)\n",
        "    return translated_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kmM0kAg7oCQ",
        "outputId": "ec40841d-ecaa-4c21-f56d-34996d194196"
      },
      "source": [
        "model.load_state_dict(torch.load(f\"/content/drive/MyDrive/AML_projekt/checkpoint_best_epoch_4.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f-mH4YP5LaJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "34d0b4ec-8535-4d9e-cc1c-0fbc276957fd"
      },
      "source": [
        "train_losses,valid_losses = train(train_iter, val_iter, model, optim, 35)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/35] complete. Train Loss: 25.999. Val Loss: 53.519\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például például például például például arra , hogy hogyan a `` igazi '' a `` ami a számára jó '' . </s>\n",
            "Epoch [2/35] complete. Train Loss: 25.212. Val Loss: 54.248\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például például abban , hogy ez a dolog a mi egyik fontos , hogy vajon milyen a mi egyik a mi egyik a mi\n",
            "Epoch [3/35] complete. Train Loss: 24.955. Val Loss: 54.245\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például jó dolog , hogy is mondjam el , hogyan lehet a mi egyik fő , hogyan lehet a mi megfelelő a mi megfelelő\n",
            "Epoch [4/35] complete. Train Loss: 24.651. Val Loss: 53.929\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez például azt jelenti , hogy a mi híres az , hogy hogyan a legerősebb a legerősebb , hogyan lehet a legerősebb . </s>\n",
            "Epoch [5/35] complete. Train Loss: 24.414. Val Loss: 54.590\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez jó dolog , ha például arra , hogy a mi része mennyire is a mi nagy része a mi egyik , hogyan a\n",
            "Epoch [6/35] complete. Train Loss: 24.164. Val Loss: 55.061\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például azt jelenti , hogy a mi nagy része a mi nagy mértékben megfelelő a mi nagy - a mi nagy - megfelelő -\n",
            "Epoch [7/35] complete. Train Loss: 23.924. Val Loss: 55.656\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez például egy jó jó jó jó dolog arra , hogy a mi `` a '' a mi '' , milyen is a mi\n",
            "Epoch [8/35] complete. Train Loss: 23.689. Val Loss: 55.531\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például jó jó eset , hogy a saját fő a számára , hogy a maga egész a maga módján tudja , milyen nagy a\n",
            "Epoch [9/35] complete. Train Loss: 23.460. Val Loss: 56.659\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez például egy jó dolog , hogy most mondd meg , hogyan lehet a mi a mi a mi a mi a mi nagy\n",
            "Epoch [10/35] complete. Train Loss: 23.261. Val Loss: 55.757\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez már jó volt , ha arról , hogy vajon milyen a legtöbb , a mi legtöbb , az egy fontos , hogy mennyire nem\n",
            "Epoch [11/35] complete. Train Loss: 23.083. Val Loss: 56.918\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez egy jó dolog , hogy azt is tudja , hogyan működik a mi a mi , ha az a fajta nagy a mi a\n",
            "Epoch [12/35] complete. Train Loss: 22.865. Val Loss: 56.854\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez egy jó jó jó volt arra , hogy vajon milyen nagy a legtöbb , ha arról , milyen hosszú a mi a mi\n",
            "Epoch [13/35] complete. Train Loss: 22.619. Val Loss: 56.944\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például egy jó terv , hogy a mi megfelelő legyen a megfelelő - és ez egy jó dolog , amikor a mi megfelelő a\n",
            "Epoch [14/35] complete. Train Loss: 22.436. Val Loss: 57.333\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például például például jó ötlet , hogy vajon a mi a számára a dolgok már a saját , hogyan a mi megfelelő a maguk\n",
            "Epoch [15/35] complete. Train Loss: 22.236. Val Loss: 57.211\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például egy jó jó jó jó jó jó jó arra , hogy vajon hogyan a a saját , amikor a saját nagy - mert\n",
            "Epoch [16/35] complete. Train Loss: 22.081. Val Loss: 57.861\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például jó volt , hogy a megfelelő valóban a megfelelő számára , vajon hogyan lehet a megfelelő a megfelelő a megfelelő a megfelelő a\n",
            "Epoch [17/35] complete. Train Loss: 21.903. Val Loss: 57.400\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez például van egy bizonyos nap , hogy a mi kis részt vett a mi `` oda '' , hogyan lehet a mi '' a\n",
            "Epoch [18/35] complete. Train Loss: 21.708. Val Loss: 58.145\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  - Ez egy jó jó volt , hogy is tudja , hogyan működik a dolgok a saját , ha azt már tudom , hogyan működik\n",
            "Epoch [19/35] complete. Train Loss: 21.597. Val Loss: 58.410\n",
            "saving state dict\n",
            "Original Sentence: This is an example to check how our model is performing.\n",
            "Translated Sentence:  Ez is valami jó eset , hogy a legtöbb jó dolog is tudni , vajon a legtöbb dolog a mi fő a mi megfelelő a\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-204a5132e429>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-69526d4cf760>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_iter, val_iter, model, optim, num_epochs, use_gpu)\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Forward, backprop, optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#, src_mask = src_mask)#, tgt_key_padding_mask=tgt_mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-94476c85954c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     49\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m     50\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n\u001b[0;32m--> 368\u001b[0;31m                                    key_padding_mask=memory_key_padding_mask)[0]\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[1;32m    983\u001b[0m                 \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                 \u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneed_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m                 attn_mask=attn_mask)\n\u001b[0m\u001b[1;32m    986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[1;32m   4261\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mbias_v\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4263\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4265\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbsz\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIin0LCDDm2E"
      },
      "source": [
        "Loading the best model for inference (based on checkpoints at each epoch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHcgjkGe5Nub"
      },
      "source": [
        "#model.load_state_dict(torch.load(f\"/content/drive/MyDrive/AML_projekt/checkpoint_best_epoch_3.pt\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyadmt_2fzQ0",
        "outputId": "0c82392a-1b8d-43ae-90e8-102a95609457"
      },
      "source": [
        "model.load_state_dict(torch.load(f\"checkpoint_best_epoch.pt\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mv7-Wpci5tLV"
      },
      "source": [
        "Some simple and not so simple sentences to translate:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTvPRVDj2qKK"
      },
      "source": [
        "sentences = [\"I can count to ten.\", \"He is in his office.\", \"He sat under a tree.\", \"There is someone at the door.\", \"The crocodiles snapped at the boat.\", \"Put the books on the table.\", \"There are many apples on the tree.\", \"The castle was heavily bombed during the war.\", \"Joe stood up and spoke to the crowd.\", \"I quickly put on my red winter jacket, black snow pants, waterproof boots, homemade mittens, and handknit scarf.\", \"What would you like for breakfast?\", \"When did the train leave the station?\", \"The man looked in the mirror and adjusted his tie.\", \"He almost managed to get his car to work.\", \"Maradona's vision, passing, ball control and dribbling skills were combined with his small stature, which gave him a low centre of gravity allowing him to maneuver better than most other football players.\", \"Due to illness and injury as well as controversial incidents on the field, Maradona had a difficult tenure in Barcelona.\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aGI99KrCgnoD",
        "outputId": "16260bd9-4227-4d19-ac64-e652df893922"
      },
      "source": [
        "sentences = sentences[:5]\n",
        "sentences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I can count to ten.',\n",
              " 'He is in his office.',\n",
              " 'He sat under a tree.',\n",
              " 'There is someone at the door.',\n",
              " 'The crocodiles snapped at the boat.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JdLqy13gfdq"
      },
      "source": [
        "reference = ['El tudok számolni tízig.', 'Az irodájában van.', 'A fa alatt ült.', 'Van valaki az ajtónál.', 'A krokodilok rátámadtak a csónakra.']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkcQEXqZD0Bw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4225e8f4-e624-4d36-f22c-02aef40043f5"
      },
      "source": [
        "for i in sentences:\n",
        "  print(str(i) + ':' + str(greeedy_decode_sentence(model,i)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I can count to ten.: Már tíz tíz tíz tudok tudok tíz tíz tíz tíz tíz tíz akár tíz tíz tíz tíz tíz tíz tíz tíz tíz tudok tudok tudok\n",
            "He is in his office.: - A szobájában van már az ő szobájában van , a szobájában van az ő szobájában van . </s>\n",
            "He sat under a tree.: Ott ült egy fa alatt , fa alatt , s ült egy fa alatt fa alatt , fa alatt fa alatt a fa alatt ült\n",
            "There is someone at the door.: Van valaki az ajtóban van valaki az ajtóban , van valaki az ajtóban , aki van az ajtóban van van az ajtó és van valaki\n",
            "The crocodiles snapped at the boat.: Az csapat a csónak a hajót felé kapott , a hajó a csónak a lépcsőn a csónak felé kapott a lépcsőn . </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wa4ltqrgdMI",
        "outputId": "e141101e-2851-4424-a437-032b77c94ad2"
      },
      "source": [
        "candidate = []\n",
        "for i in sentences:\n",
        "  candidate.append(str(greeedy_decode_sentence(model,i)))\n",
        "print(candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' Már tíz tíz tíz tudok tudok tíz tíz tíz tíz tíz tíz akár tíz tíz tíz tíz tíz tíz tíz tíz tíz tudok tudok tudok', ' - A szobájában van már az ő szobájában van , a szobájában van az ő szobájában van . </s>', ' Ott ült egy fa alatt , fa alatt , s ült egy fa alatt fa alatt , fa alatt fa alatt a fa alatt ült', ' Van valaki az ajtóban van valaki az ajtóban , van valaki az ajtóban , aki van az ajtóban van van az ajtó és van valaki', ' Az csapat a csónak a hajót felé kapott , a hajó a csónak a lépcsőn a csónak felé kapott a lépcsőn . </s>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HKbHNKAhdGc",
        "outputId": "f85e228f-2a88-497f-aa7e-8ddfdc2d7e38"
      },
      "source": [
        "reference_tok = []\n",
        "candidate_tok = []\n",
        "for i in range(len(candidate)):\n",
        "  reference_tok.append(word_tokenize(reference[i]))\n",
        "  candidate_tok.append(word_tokenize(candidate[i]))\n",
        "reference_tok"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['El', 'tudok', 'számolni', 'tízig', '.'],\n",
              " ['Az', 'irodájában', 'van', '.'],\n",
              " ['A', 'fa', 'alatt', 'ült', '.'],\n",
              " ['Van', 'valaki', 'az', 'ajtónál', '.'],\n",
              " ['A', 'krokodilok', 'rátámadtak', 'a', 'csónakra', '.']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ersLbAWw5-dJ"
      },
      "source": [
        "This model works relatively well on shorter simple sentences, but fails to give a sensible translation on longer sentences. Also it often repeats the same words twice in a sentence even in the short ones."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kl14AD0_gNRN"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5Icp4Xc6NCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ab61ef-6c5c-42f8-fc19-a01266f4f737"
      },
      "source": [
        "#reference = [['this', 'is', 'a', 'test'], ['this', 'is' 'test']]\n",
        "#candidate = ['this', 'is', 'a', 'test']\n",
        "sum_score = 0\n",
        "for i in range(len(candidate)):\n",
        "  score = sentence_bleu(reference_tok[i], candidate_tok[i])\n",
        "  print(score)\n",
        "  sum_score += score\n",
        "print('The average bleu score accross sentences: ' + str(sum_score/len(candidate_tok)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0.6147881529512643\n",
            "0.447213595499958\n",
            "0\n",
            "0.5885661912765424\n",
            "The average bleu score accross sentences: 0.3301135879455529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rP26QeJvLEBf"
      },
      "source": [
        "The average bleu score accross sentences: 0.3181742372437443 (first run) \\\\\n",
        "The average bleu score accross sentences: 0.3301135879455529 (second run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnqpTJKEgLCy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1206ffc-6748-4a6e-fddf-190219bfcbc9"
      },
      "source": [
        "input_sentences = []\n",
        "output_sentences = []\n",
        "\n",
        "\n",
        "count = 0\n",
        "for line in open(r'/content/drive/MyDrive/AML_projekt/hun.txt', encoding=\"utf-8\"):\n",
        "    count += 1\n",
        "\n",
        "    #if count > NUM_SENTENCES:\n",
        "     #   break\n",
        "\n",
        "    if '\\t' not in line:\n",
        "        continue\n",
        "\n",
        "    input_sentence, output_sentence = line.rstrip().split('\\t')[0], line.rstrip().split('\\t')[1]\n",
        "\n",
        "    input_sentences.append(input_sentence)\n",
        "    output_sentences.append(output_sentence)\n",
        "\n",
        "print(\"num samples input:\", len(input_sentences))\n",
        "print(\"num samples output:\", len(output_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num samples input: 87437\n",
            "num samples output: 87437\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbY_96YDPVuu",
        "outputId": "1841568e-daa9-4b24-b111-244673a0a6ea"
      },
      "source": [
        "input_sentences[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hi.',\n",
              " 'Hi.',\n",
              " 'Hi.',\n",
              " 'Run!',\n",
              " 'Run!',\n",
              " 'Run.',\n",
              " 'Run.',\n",
              " 'Who?',\n",
              " 'Wow!',\n",
              " 'Wow!',\n",
              " 'Wow!',\n",
              " 'Wow!',\n",
              " 'Wow!',\n",
              " 'Fire!',\n",
              " 'Fire!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHgBa3HXPY7a",
        "outputId": "447075c3-a31f-4993-da21-f0925bac6266"
      },
      "source": [
        "output_sentences[:15]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Cső!',\n",
              " 'Helóka!',\n",
              " 'Csövi!',\n",
              " 'Fuss!',\n",
              " 'Rohanj!',\n",
              " 'Fuss!',\n",
              " 'Rohanj!',\n",
              " 'Ki?',\n",
              " 'Hűha!',\n",
              " 'Váó!',\n",
              " 'Aszta!',\n",
              " 'Tyűha!',\n",
              " 'Nahát!',\n",
              " 'Tűz!',\n",
              " 'Lőj!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "eYXupPatSAFi",
        "outputId": "7404ced4-eaa8-4b2c-a987-6fc1183cf9de"
      },
      "source": [
        "candidate = []\n",
        "for i in input_sentences:\n",
        "  candidate.append(str(greeedy_decode_sentence(model,i)))\n",
        "print(candidate[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-5964bc487851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_sentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mcandidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgreeedy_decode_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-d06ae00ba0d6>\u001b[0m in \u001b[0;36mgreeedy_decode_sentence\u001b[0;34m(model, sentence)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mnp_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'-inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp_mask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mnp_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0madd_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTGT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtranslated_sentence\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0madd_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-94476c85954c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     49\u001b[0m         output = self.decoder(tgt, memory, tgt_mask=tgt_mask, memory_mask=memory_mask,\n\u001b[1;32m     50\u001b[0m                               \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                               memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    232\u001b[0m                          \u001b[0mmemory_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmemory_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                          \u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtgt_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                          memory_key_padding_mask=memory_key_padding_mask)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m    364\u001b[0m                               key_padding_mask=tgt_key_padding_mask)[0]\n\u001b[1;32m    365\u001b[0m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtgt\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mtgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m         tgt2 = self.multihead_attn(tgt, memory, memory, attn_mask=memory_mask,\n\u001b[1;32m    368\u001b[0m                                    key_padding_mask=memory_key_padding_mask)[0]\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/normalization.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         return F.layer_norm(\n\u001b[0;32m--> 170\u001b[0;31m             input, self.normalized_shape, self.weight, self.bias, self.eps)\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 layer_norm, (input,), input, normalized_shape, weight=weight, bias=bias, eps=eps)\n\u001b[1;32m   2094\u001b[0m     return torch.layer_norm(input, normalized_shape, weight, bias, eps,\n\u001b[0;32m-> 2095\u001b[0;31m                             torch.backends.cudnn.enabled)\n\u001b[0m\u001b[1;32m   2096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIhGOIvvf3qy",
        "outputId": "a7136ca4-f7e3-4d1c-acd1-d591265cde79"
      },
      "source": [
        "len(candidate)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10979"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uxspw3fgCS2"
      },
      "source": [
        "reference = output_sentences[:10979]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6VXKwtqPL23",
        "outputId": "0a628dfe-d222-4e97-d933-a5c303074940"
      },
      "source": [
        "reference_tok = []\n",
        "candidate_tok = []\n",
        "for i in range(len(candidate)):\n",
        "  reference_tok.append(word_tokenize(reference[i]))\n",
        "  candidate_tok.append(word_tokenize(candidate[i]))\n",
        "reference_tok[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Cső', '!'],\n",
              " ['Helóka', '!'],\n",
              " ['Csövi', '!'],\n",
              " ['Fuss', '!'],\n",
              " ['Rohanj', '!'],\n",
              " ['Fuss', '!'],\n",
              " ['Rohanj', '!'],\n",
              " ['Ki', '?'],\n",
              " ['Hűha', '!'],\n",
              " ['Váó', '!']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMBr3KRQPyh-",
        "outputId": "de0deb9b-f30c-401f-9525-beadf18b0230"
      },
      "source": [
        "len(input_sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2rPgJnhPkMg",
        "outputId": "dd40ee36-d6f5-4eef-b156-af9eadbd35a1"
      },
      "source": [
        "sum_score = 0\n",
        "for i in range(len(candidate_tok)):\n",
        "  score = sentence_bleu(reference_tok[i], candidate_tok[i])\n",
        "  #print(score)\n",
        "  sum_score += score\n",
        "print('The average bleu score accross sentences: ' + str(sum_score/len(candidate_tok)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The average bleu score accross sentences: 0.31839040906794214\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67_z_GboRomA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
